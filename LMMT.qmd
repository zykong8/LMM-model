---
title: "LMM"
format: html
editor: visual
---

# 1. What is mixed effects modelling and why does it matter?

生态和生物数据往往复杂而混乱。我们可以有不同的分组因素，如种群、物种、收集数据的地点等。样本量也可能存在一些不足，特别是当我们试图拟合具有许多参数的复杂模型时。除此之外，我们的数据点可能不是真正独立的。例如，我们可能会在网站内使用样方来收集数据（因此我们的数据是有结构的：样方嵌套在网站内）。

这就是为什么开发了混合模型，以处理如此混乱的数据，并允许我们使用所有数据，即使我们有低样本量、结构化数据和许多协变量需要拟合。哦，最重要的是，与运行标准线性模型相比，混合模型使我们能够节省自由度！听起来不错，不是吗？

我们在这里只介绍线性混合模型，但如果你想“扩展”你的线性模型，不用担心：也有广义的线性混合效应模型。

# 2. Explore the data

我们将专注于一个虚构的研究系统，龙，这样我们就不必因为这个例子的细节而分心。想象一下，我们决定训练龙，所以我们去了山区，收集了龙智能的数据（testScore）作为先决条件。我们在八个不同山脉的三个地点对不同体长的个体进行了采样。首先加载数据并查看它们。

```{r}
rm(list = ls());gc()
pacman::p_unload(pacman::p_loaded(), character.only = TRUE)
load("Mixed-Model-Code-master/dragons.RData")
head(dragons)
```

假设我们想知道龙的体长如何影响它们的考试成绩。 你不需要担心解释变量的分布。看看响应变量的分布：

```{r}
hist(dragons$testScore)  # seems close to a normal distribution - good!
```

在继续之前，对解释变量进行标准化是一种很好的做法，这样它们的平均值为零（“居中”），标准偏差为一（“缩放”）。它确保估计的系数都在同一尺度上，从而更容易比较效果大小。你可以使用scale（）来做到这一点：

```{r}
dragons$bodyLength2 <- scale(dragons$bodyLength, center = TRUE, scale = TRUE)
```

scale（）将数据居中（从列中的值中减去列平均值），然后对其进行缩放（居中的列值除以列的标准偏差）。

回到我们的问题：训练成绩是否受到体长的影响？

# 3. Fit all data in one analysis

分析这些数据的一种方法是将线性模型拟合到我们所有的数据中，暂时忽略这些地点和山脉。

将testScore作为响应变量，bodyLength2作为预测变量来拟合模型，并查看输出：

```{r}
basic.lm <- lm(testScore ~ bodyLength2, data = dragons)
summary(basic.lm)
```

让我们用ggplot2绘制数据。

```{r}
library(tidyverse)  # load the package containing both ggplot2 and dplyr

(prelim_plot <- ggplot(dragons, aes(x = bodyLength, y = testScore)) +
  geom_point() +
  geom_smooth(method = "lm"))
  
```

请注意，将整个ggplot代码放在括号（）中会创建图形，然后在绘图查看器中显示。如果你没有括号，那么你只创建了对象，但还没有将其可视化。然后，你必须调用该对象，以便在创建“prelim_plot”对象后，只需键入prelim_plot即可显示它。

好吧，从线性模型和图来看，看起来更大的龙在我们的训练测试中表现更好。这似乎有点奇怪：尺寸不应该真正影响考试成绩。

但是…这些假设得到满足了吗？ 绘制残差图：红线应近乎平坦，如灰色虚线：下面的图显示结果不是很理想，但由于这是一个虚构的例子，我们将使用它来处理你自己的数据，要小心：样本量越大，你期望看到的趋势就越小

```{r}
plot(basic.lm, which = 1) 
```

快速浏览一下qqplot：理想情况下，点应该落在斜线上：在极端情况下有点偏离，但这种情况经常发生；看起来也不太糟糕

```{r}
plot(basic.lm, which = 2)
```

但是，观察独立性呢？我们的数据独立吗？我们从八个山脉采集了多个样本。每个山脉内的数据比不同山脉的数据更相似，这是完全合理的：它们是相互关联的。

看看数据，看看上面的是否属实：

```{r}
boxplot(testScore ~ mountainRange, data = dragons) 
```

我们还可以按山脉绘制它：

```{r}
(colour_plot <- ggplot(dragons, aes(x = bodyLength, y = testScore, colour = mountainRange)) +
  geom_point(size = 2) +
  scale_color_brewer(
    palette = "Dark2"
  ) +
  theme_classic() +
  theme(legend.position = "none"))
```

从上面的图表可以看出，不同山脉在龙身长度和训练成绩上都有所不同。这证实了我们在每个范围内的观察不是独立的。我们不能忽视这一点：正如我们开始看到的那样，这可能会导致一个完全错误的结论。

那我们该怎么办？

# 4. Run multiple analyses

我们可以进行许多单独的分析，并为每个山脉拟合回归。 让我们快速浏览一下按山脉划分的数据。我们使用facet_wrap来做到这一点：

```{r}
(split_plot <- ggplot(aes(bodyLength, testScore), data = dragons) + 
  geom_point() + 
  facet_wrap(~ mountainRange) + # create a facet for each mountain range
  xlab("length") + 
  ylab("test score"))
```

这是八个分析。哦，等等，我们在每个山脉都有不同的地点，就像山脉一样，它们不是独立的……所以我们可以分别对每个山脉中的每个地点进行分析。 要做到这一点，我们必须估计每个回归的斜率和截距参数。这是两个参数，三个地点和八个山脉，这意味着48个参数估计（2 x 3 x 8=48）！此外，每次分析的样本量仅为20条（每个地点的龙）。

这带来了问题：我们不仅大大减少了样本量，而且通过进行多重比较，也增加了I型错误（错误地拒绝了零假设）的可能性。不太理想！

# 5. Modify the current model

我们希望使用所有数据，但要考虑来自不同山脉的数据（让我们暂停一秒钟，让事情变得更简单）。 将山脉作为固定效应添加到我们的基本模型中。

```{r}
mountain.lm <- lm(testScore ~ bodyLength2 + mountainRange, data = dragons)
summary(mountain.lm)
```

现在身体长度并不重要。但让我们想想我们在这里做什么。上述模型正在估算山脉之间的训练分数差异——我们可以在summary（）返回的模型输出中看到所有山脉。但我们对量化每个特定山脉的训练成绩不感兴趣：我们只是想知道身体长度是否会影响训练成绩，我们想简单地控制来自山脉的变化。

这就是我们所说的“随机因素”，因此我们得出了混合效应模型。太棒了！

# 6. Mixed effects models

混合模型在这里是一个不错的选择：它将允许我们使用我们拥有的所有数据（更高的样本量），并考虑来自现场位点和山脉的数据之间的相关性。我们还将估计更少的参数，并避免使用单独回归时遇到的多重比较问题。

我们将在lme4中工作，因此请加载包（如果您的计算机上没有lme4，请使用install.packes）。

```{r}
library(lme4)
```

## Fixed and random effects

让我们先来谈谈固定效应和随机效应之间的区别。重要的是，这种差异与变量本身关系不大，而与你的研究问题关系很大！在许多情况下，同一变量可以被视为随机或固定效应（有时甚至同时存在！），因此请务必参考您的问题和假设来相应地构建模型。

> 我的变量应该是固定的还是随机的？ 广义上讲，固定效应是我们预期会对因变量或响应变量产生影响的变量：它们是标准线性回归中的解释变量。在我们的案例中，我们有兴趣就龙的身体长度如何影响龙的训练成绩得出结论。因此，体长是一个固定效应，训练成绩是因变量。 另一方面，随机效应通常是我们试图控制的分组因素。它们总是分类的，因为你不能强迫R将连续变量视为随机效应。很多时候，我们对它们对响应变量的影响并不特别感兴趣，但我们知道它们可能会影响我们看到的模式。 此外，我们随机效应的数据只是所有可能性的一个样本：在不受时间和资金限制的情况下，我们可能会对龙生活的每一座山、全国的每一所学校、盒子里的每一块巧克力进行抽样，但我们通常倾向于根据代表性抽样将结果推广到整个人群。我们不关心估计A学校的学生比B学校的学生做得好多少，但我们知道他们各自的老师可能是他们成绩不同的原因，我们想知道当我们预测Z学校学生的成绩时，有多少差异可以归因于此。

在我们的特殊情况下，我们希望控制山脉的影响。我们还没有对世界上所有的山脉进行采样（我们有八个），所以我们的数据只是所有现有山脉的样本。我们对每个特定山脉对训练分数的影响并不感兴趣：我们希望我们的模型也能推广到其他山脉的龙！然而，我们知道范围内的训练分数可能是相关的，所以我们想对此进行控制。

如果我们事先特别选择了八个特定的山脉，并且我们对这些山脉感兴趣并想对其进行预测，那么山脉将被拟合为固定效应。

> 更多关于随机效应的信息 请注意，黄金法则是，你通常希望你的随机效应至少有五个级别。因此，例如，如果我们想控制龙的性别对智力的影响，我们可以将性别（一个两级因素：男性或女性）视为固定的，而不是随机的。 简单地说，这是因为估计少数数据点的方差非常不精确。从数学上讲，你可以，但你对它没有多大信心。如果你只有两三个层次，模型将很难对方差进行划分——它会给你一个输出，但不一定是你可以信任的输出。
>
> 最后，请记住，random这个名字与数学随机性没有太大关系。是的，这很令人困惑。现在把它们看作是分组变量。严格来说，这一切都是为了让我们的模型代表我们的问题，并得到更好的估计。希望我们接下来的几个例子能帮助你理解它们是如何以及为什么被使用的。

最后，最大的问题是：你想做什么？你想预测什么？你需要控制的变化（又称“噪音”）是什么？

## Let’s fit our first mixed model

我们有一个响应变量，即训练成绩（testScore），我们试图通过将身体长度拟合为固定效应来解释testScore的部分变化。但响应变量有一些与山脉相关的残差变化（即无法解释的变化）。通过使用随机效应，我们通过方差对无法解释的变异进行建模。

请注意，我们的问题在这里略有变化：虽然我们仍然想知道龙的身体长度和测试成绩之间是否存在关联，但我们想知道在控制了山脉的变化后，这种关联是否存在。

我们将使用语法（1\|variableName）来拟合随机效应：

```{r}
mixed.lmer <- lmer(testScore ~ bodyLength2 + (1|mountainRange), data = dragons)
summary(mixed.lmer)
```

一旦我们考虑了山脉，很明显，龙的身体长度并不能解释考试成绩的差异。它是如何显而易见的？我听到你说？

看看summary输出：注意模型估计值如何小于其相关误差？这意味着效应或斜率不能与零区分开。

![](images/clipboard-4030600269.png)

> -   随机效应部分告诉你在分组因子的水平之间找到了多少方差，以及残差的方差
>
> -   固定效应部分与线性模型输出非常相似：截距和误差估计、斜率和误差估计

请记住，山脉的随机效应旨在捕捉山脉对龙测试成绩的所有影响——无论我们是否明确观察到这些影响，无论这些影响是大是小等等。这可能是许多微小的影响，当它们结合在一起时，会影响测试成绩，这就是我们希望控制的。

我们可以看到mountainRange=339.7的方差。山脉显然很重要：它们解释了许多变化。我们怎么知道？我们可以将山脉的方差除以总方差：

```{r}
339.7/(339.7 + 223.8)  # ~60 %
```

因此，山脉之间的差异解释了我们的固定效应解释的方差后“剩余”的约60%的方差。

与往常一样，最好看看图表来检查我们的假设：看起来不错，没有明显的趋势。

```{r}
plot(mixed.lmer)  # looks alright, no patterns evident
```

再来看看QQ图：点很好地落在了对角线上—太好了！

```{r}
qqnorm(resid(mixed.lmer))
qqline(resid(mixed.lmer))  # points fall nicely onto the line - good!
```

## Types of random effects

在我们进一步讨论之前，让我们回顾一下上面的语法，并谈谈交叉和嵌套的随机效应。在脑子里把这些弄清楚是有用的。 提醒：因子就是任何分类自变量。 上面，我们使用（1\|mountainRange）来拟合我们的随机效应。`|`运算符右侧的任何元素都是一个因子，被称为该术语的“分组因子”。 随机效应（因素）可以交叉或嵌套，这取决于变量之间的关系。我们来看看。

### Crossed random effects

小心命名。有“分层线性模型”（HLM）或“多级模型”，但虽然所有HLM都是混合模型，但并非所有混合模型都是分层的。这是因为你可以交叉（或部分交叉）不代表层次结构中级别的随机因素。

例如，想想我们的研究，你在不同的山脉（背景）上监测龙（受试者），想象一下，我们通过多次测试来收集每条龙的多个观察结果（并冒着伪复制的风险——但稍后会详细介绍）。由于我们的龙会飞，很容易想象我们可能会在不同的山脉上观察到同一条龙，但我们也可能不会看到所有的龙都访问了所有的山脉。因此，我们有可能观察到每条山脉中的每一条龙（交叉），或者至少观察到一些山脉中的一些龙（部分交叉）。然后，我们将龙和山脉的身份视为（部分）交叉的随机效应。

让我们用另一个例子重复一遍：当所有受试者都经历了该效应的所有层次时，该效应（完全）交叉。例如，如果你对生长在季节性森林中的幼苗进行施肥实验，并在每个季节随时间（比如3年）进行重复测量，你可能想有一个称为季节（夏季1、秋季1、冬季1、春季1、夏季2、…、春季3）的交叉因子，即每年每个季节的因子。这种分组因素将解释这样一个事实，即实验中的所有植物，无论固定（处理）效应如何（即是否施肥），都可能在第二年经历了非常炎热的夏天，或者在第三年经历了多雨的春天，这些条件可能会对预期的模式造成干扰。你甚至不需要相关的气候数据来解释它！你只知道，春季3的所有观察结果可能彼此更相似，因为它们经历了相同的环境，而不是因为它们对你的处理有反应。

如果这听起来令人困惑，别担心，lme4可以很好地处理部分和完全交叉的因素。现在，让我们看看嵌套的随机效应以及如何指定它们。

### Nested random effects

如果你不确定什么是嵌套随机效应，想想那些俄罗斯嵌套娃娃。我们已经暗示过，我们称这些模型为层次模型：其中通常有一个标准化或抽样分层的元素。

再以我们的施肥实验为例；假设你在每个样方上有50棵幼苗，有10个对照和10个实验。总共有1000棵幼苗。假设你在3年的每一季都出去收集一次。在每株植物上，你测量5片叶子的长度。那是…。（很多数学题）……5片叶子x50株植物x20张床x4个季节x3年…。。60000次测量！

但是，如果你使用简单的线性回归进行分析，例如 `leafLength~treatment`，你将犯下伪复制罪，或者通过使用非独立数据大幅增加样本量。如果样本量为60000，你几乎肯定会得到一个“显著”的治疗效果，这可能根本没有生态意义。它违反了线性回归的核心——观测独立性的假设。

这就是我们嵌套娃娃的用武之地；植物内的叶子和样方内的植物可能彼此更相似（例如分别出于遗传和环境原因）。因此，您可以添加一个随机效应结构来解释这种嵌套：leafLength \~ treatment + (1\|Bed/Plant/Leaf)。

这样，该模型将考虑数据中的非独立性：重复采样相同的叶子，在个体上测量多片叶子，将植物分组到可能接受不同日照量的样方上，等等。

我们之前提到的交叉效应呢？如果所有季节的叶子都被测量过，那么你的模型就会变成这样：leafLength \~ treatment + (1\|Bed/Plant/Leaf) + (1\|Season)

> 隐式嵌套与显式嵌套
>
> 为了让事情更容易，正确地编写数据并避免隐式嵌套。 为了解决这个问题，让我们看看我们研究的另一个方面：我们不仅在多个山脉收集了龙的数据，而且在这些山脉内的几个地点也收集了龙。如果你不记得了，再看看数据：
>
> ```{r}
> head(dragons)  # we have site and mountainRange
> str(dragons)  # we took samples from three sites per mountain range and eight mountain ranges in total
> ```
>
> 就像我们对山脉所做的那样，我们必须假设在我们的站点内收集的数据可能是相关的，因此我们应该将站点作为额外的随机效应纳入我们的模型中。
>
> 我们的场地变量是一个三级因素，场地称为a、b和c。场地在山脉内的嵌套是隐含的——如果不将我们的场地分配给特定的山脉，我们的场地就没有意义，即巴伐利亚山脉的b场地与中央山脉的b地点之间没有任何联系。为了避免将来的混淆，我们应该创建一个显式嵌套的新变量。我们称之为示例：
>
> ```{r}
> dragons <- within(dragons, sample <- factor(mountainRange:site))
> ```
>
> 现在很明显，我们有24个样本（8个山脉x 3个地点），而不仅仅是3个：我们的样本是一个24级因子，我们应该使用它，而不是在我们的模型中使用地点：每个地点都属于一个特定的山脉。
>
> 综上所述：对于嵌套随机效应，该因素仅出现在另一个因素的特定水平内（每个地点都属于特定的山脉，并且只属于该山脉）；对于交叉效应，一个给定的因素出现在另一个因素的多个层次上（龙出现在多个山脉内）。或者你可以记住，如果你的随机效应没有嵌套，那么它们就是交叉的！

## Our second mixed model

基于上述情况，使用以下规范是错误的，因为这意味着在8个山脉（交叉）中的每一个都只有三个观测点：

```{r}
# treats the two random effects as if they are crossed
mixed.WRONG <- lmer(testScore ~ bodyLength2 + (1|mountainRange) + (1|site), data = dragons)
summary(mixed.WRONG)
```

![](images/clipboard-1325389163.png)

> 注意：观察结果的分组时错误的：当我们实际采样了24个不同地点时，实际上只有3个地点。

但我们可以继续拟合一个新模型，该模型通过使用我们的样本变量，考虑了山脉之间的差异以及山脉内地点之间的差异。我们的问题又稍微调整了一下：在控制了山脉和山脉内地点的变化后，龙的体长和智力之间是否存在关联？

```{r}
# the syntax stays the same, but now the nesting is taken into account
dragons$sample <- factor(paste(dragons$mountainRange, dragons$site, sep = "_"))
mixed.lmer2 <- lmer(testScore ~ bodyLength2 + (1|mountainRange) + (1|sample), data = dragons)  
summary(mixed.lmer2)
```

![](images/clipboard-2001834813.png)

> 注意：在这里，模型识别出有24个样本分布在8个范围内。

在这里，我们试图考虑所有山脉水平和所有场地水平的影响，我们希望我们的随机效应已经吸收了所有这些影响，这样我们就可以在模型中控制它们。

为了记录在案，您还可以使用以下语法，如果您阅读更多关于混合模型的内容，您经常会遇到它：`(1|mountainRange/site)` or  `(1|mountainRange) + (1|mountainRange:site)` 。

但是，建议正确设置变量，并确保在变量中明确说明嵌套，这样就不必记住指定嵌套。

让我们再次绘制这个图—可视化正在发生的事情总是有帮助的。你应该能够看到八个山脉，其中有三个地点（不同的色点），每个地点都有一条线。

```{r}
# a panel for each mountain range
(mm_plot <- ggplot(dragons, aes(x = bodyLength, y = testScore, colour = site)) +
      facet_wrap(~mountainRange, nrow=2) +
      geom_point(alpha = 0.5) +
      theme_classic() +
      # adding predicted line from mixed model 
      geom_line(data = cbind(dragons, pred = predict(mixed.lmer2)), aes(y = pred), size = 1) +
      theme(legend.position = "none",
            # adding space between panels
            panel.spacing = unit(2, "lines"))
)
```

## Introducing random slopes

您可能已经注意到，上图中的所有线条都是平行的：这是因为到目前为止，我们只拟合了随机截距模型。随机截距模型允许截距随随机效应的每个级别而变化，但保持它们之间的斜率恒定。因此，在我们的案例中，使用这个模型意味着我们期望所有山脉中的龙在体长和智力之间表现出相同的关系（固定斜率），尽管我们承认一些种群可能一开始就更聪明或更笨（随机截距）。

现在，在生命科学中，我们可能更经常地假设并非所有人群都会表现出完全相同的关系，例如，如果你的研究地点/人群相距甚远，并且存在一些相对重要的环境、遗传等差异。因此，我们经常想要拟合一个随机斜率和随机截距模型。也许在非常寒冷的山脉和非常温暖的山脉中，龙已经进化出不同的身体形态来保温，因此即使它们比平均水平小，也可能很聪明。

我们只需要对模型进行一个更改，以允许随机斜率和截距，那就是将固定变量添加到随机效应括号中：

```{r}
mixed.ranslope <- lmer(testScore ~ bodyLength2 + (1 + bodyLength2|mountainRange/site), data = dragons) 

summary(mixed.ranslope)
```

在这里，我们说，让我们将龙的智力建模为身体长度的函数，知道种群有不同的智力基线，并且种群之间的关系可能会有所不同。

让我们用快速绘图来看看（我们将在下一节中更详细地绘制预测）。注意到不同地点和山脉的坡度不再平行了吗？

```{r}
### plot
(mm_plot <- ggplot(dragons, aes(x = bodyLength, y = testScore, colour = site)) +
      facet_wrap(~mountainRange, nrow=2) +   # a panel for each mountain range
      geom_point(alpha = 0.5) +
      theme_classic() +
      geom_line(data = cbind(dragons, pred = predict(mixed.ranslope)), aes(y = pred), size = 1) +  # adding predicted line from mixed model 
      theme(legend.position = "none",
            panel.spacing = unit(2, "lines"))  # adding space between panels
)
```

干得好，来到这里！现在，您已经拟合了随机截距和随机斜率混合模型，并且知道如何考虑分层和交叉随机效应。你看到，如果不考虑数据中的相关性，可能会导致误导性的结果—在我们考虑到来自山脉的变化之前，身体长度似乎会影响测试成绩。我们现在可以看到，身体长度不会影响考试成绩—太好了！我们可以选择较小的龙进行任何未来的训练—较小的龙应该更容易管理！

如果你特别感兴趣，下一节将为你提供一些展示模型结果的选项，在最后一节“额外”中，你可以了解模型选择难题。如果你喜欢的话，这里还有更多的代码可以通过。

## Presenting your model results

一旦你得到了你的模型，你就必须以更好的形式呈现它。

### Plotting model predictions

通常，你会想把你的模型想象成一条回归线，周围有一些误差，就像你想象一个简单的线性模型一样。但是，ggplot2统计选项不是为了正确估计混合效应模型对象而设计的，因此我们将使用ggeffects包来帮助我们绘制图表。

```{r}
library(ggeffects)  # install the package first if you haven't already, then load it

# Extract the prediction data frame
pred.mm <- ggpredict(mixed.lmer2, terms = c("bodyLength2"))  # this gives overall predictions for the model

# Plot the predictions 

(ggplot(pred.mm) + 
   geom_line(aes(x = x, y = predicted)) +          # slope
   geom_ribbon(aes(x = x, ymin = predicted - std.error, ymax = predicted + std.error), 
               fill = "lightgrey", alpha = 0.5) +  # error band
   geom_point(data = dragons,                      # adding the raw data (scaled values)
              aes(x = bodyLength2, y = testScore, colour = mountainRange)) + 
   labs(x = "Body Length (indexed)", y = "Test Score", 
        title = "Body length does not affect intelligence in dragons") + 
   theme_minimal()
)
```

如果你想想象这些关系是如何根据不同水平的随机效应而变化的呢？您可以在ggpredict（）函数中指定type=“random”（表示“随机效果”），并将随机效果名称添加到terms参数中。

我们还演示了一种使用ggEffects的plot（）函数更快地绘制图形的方法：

```{r}
ggpredict(mixed.lmer2, terms = c("bodyLength2", "mountainRange"), type = "random") %>% 
   plot() +
   labs(x = "Body Length", y = "Test Score", title = "Effect of body size on intelligence in dragons") + 
   theme_minimal()
```

从这张图中，你可以清楚地看到随机截距和固定斜率。在评估模型的质量时，最好将原始数据、summary输出和预测放在一起查看，以确保您了解发生了什么（并且您正确地指定了模型）。

如果你有兴趣显示随机效应水平之间的变化，另一种可视化混合模型结果的方法是，如果你有一个随机斜率模型，绘制截距和斜率与整体模型估计值的偏差：

```{r}
library(sjPlot)

# Visualise random effects 
(re.effects <- plot_model(mixed.ranslope, type = "re", show.values = TRUE))

# show summary
summary(mixed.ranslope)

```

小心！您看到的值不是实际值，而是模型summary中发现的一般截距或斜率值与此特定随机效应水平的估计值之间的差异。例如，Maritime山脉中龙的关系斜率为（-2.91+0.67）=-2.24，截距为（20.77+51.43）=72.20。

### Tables

对于lme4，如果你在找可视化的表格，我建议你使用stargazer包。

```{r}
library(stargazer)
```

这里有一个快速的例子——只需将您的模型名称（在本例中为mixed.lmer2）插入stargazer函数即可。我将type设置为“text”，这样您就可以在控制台中看到表格。我通常会这样调整表格，直到我满意为止，然后使用type=“latex”导出它，但如果你不是latex用户，“html”可能对你更有用。

如果你感兴趣，可以进一步探索这张表——你会改变什么？你会摆脱什么？

```{r}
stargazer(mixed.lmer2, type = "text",
          digits = 3,
          star.cutoffs = c(0.05, 0.01, 0.001),
          digit.separator = "")
```

## EXTRA: P-values and model selection

在选择模型时，请务必非常小心。专注于你的问题，不要随意地从模型中插入和删除变量，直到你做出“有意义”的事情。始终根据生物学/生态学选择变量：我可能会使用模型选择来检查几个非焦点参数，但在大多数情况下，我保持模型的“核心”不变。定义你的目标和问题，并专注于此。此外，不要把所有可能的变量都放进去（即不要过度拟合）。记住，根据经验，你需要的数据是你试图估计的参数的10倍。

## Fixed effects structure

在我们开始之前，再次强调：在信任模型选择之前要三思而后行！

你们中的大多数人可能主要对固定效应感兴趣，所以让我们从这里开始。默认情况下，lme4不会为参数输出p值。这是该包作者有意识地做出的选择，因为p值存在许多问题（我相信你知道这些争论！）。

你不可避免地会寻找一种方法来评估你的模型，所以这里有一些关于如何在线性混合模型（LMM）中进行假设检验的解决方案：

从最差到最好：

-   Wald Z检验

-   Wald t检验（但LMM需要平衡和嵌套）

-   Likelihood ratio tests：似然比检验（通过方差分析（anova()）或drop1()）

-   MCMC或参数bootstrap置信区间

我认为MCMC和bootstrap在本次研讨会上有点遥不可及，所以让我们使用anova（）快速进行似然比测试。对于大样本量，基于似然比的p值通常被认为是可以的。注意：对于小样本量，您可能希望使用Kenward-Roger或Satterthwaite近似法（用于REML模型）来推导p值。查看pbkrtest包。

调整模型，完整模型和简化模型，其中我们放弃了固定效果（bodyLength2）：

```{r}
full.lmer <- lmer(testScore ~ bodyLength2 + (1|mountainRange) + (1|sample), 
				  data = dragons, REML = FALSE)
reduced.lmer <- lmer(testScore ~ 1 + (1|mountainRange) + (1|sample), 
					     data = dragons, REML = FALSE)
```

进行比较：

```{r}
anova(reduced.lmer, full.lmer)  # the two models are not significantly different
```

请注意，我们已经用REML=FALSE对模型进行了拟合。

REML代表受限（或“残差”）最大似然，是线性混合模型的默认参数估计标准。正如你可能猜到的，ML代表最大似然——你可以在调用lmer时设置REML=FALSE来使用ML估计。然而，众所周知，ML估计存在偏差，而REML的偏差通常较小，因此通常更倾向于方差分量的REML估计。这就是为什么在我们之前的模型中，我们跳过了设置REML——我们只是将其保留为默认值（即REML=TRUE）。

REML假设固定效应结构是正确的。在比较具有不同固定效应的模型时，您应该使用最大似然法，因为ML不依赖于固定效应的系数，这就是为什么我们在调用中添加REML=FALSE来重新调整上面的完整和简化模型。

即使您使用ML来比较模型，您也应该报告最终“最佳”REML模型的参数估计值，因为ML可能会低估随机效应的方差。

注2：还可以使用AICcmodavg包中的AICc函数对模型进行比较。Akaike信息准则（AIC）是模型质量的度量。AICc在估计AIC时校正了小样本量产生的偏差。一般来说，如果模型之间的AICc单位在2个以内，它们就非常相似。在5个单位内，它们非常相似，超过10个单位的差异，你可能会对AICc较低的模型感到满意。然而，与p值一样，没有总是正确的“硬线”。

注3：在评估显著性时，并没有一种公认的方法来处理混合模型中随机效应的方差。p值和效应大小都有问题，尽管据我所知，p值似乎比效应大小引起更多的分歧，至少在R社区是这样。

### Random effects structure

现在你可能想知道如何选择随机效应。总的来说，我建议你考虑一下你的实验设计、系统收集的数据，以及你的问题。

如果你的随机效应是为了处理伪复制，那么它们是否“显著”并不重要：它们是你设计的一部分，必须包括在内。想象一下，我们多次测试我们的龙——然后我们必须将龙的身份作为随机效应进行匹配。

另一方面，如果你试图解释你认为可能很重要的其他可变性，那就有点难了。想象一下，我们在龙的寿命（比如100年）内测量了它们的质量。然后，我们可能想将年份作为随机效应来解释任何时间变化——也许有些年份受到了干旱的影响，资源稀缺，因此龙的数量受到了负面影响。年份肯定是一个合理的随机效应，尽管严格来说不是必须的。

当涉及到这种随机效应时，您可以使用模型选择来帮助您决定保留什么。根据Zuur的建议，我们使用REML估计器来比较具有不同随机效应的模型（我们保持固定效应不变）。（Zuur：“两个具有嵌套随机结构的模型不能用ML完成，因为方差项的估计值是有偏差的。”）

注意：不要同时改变随机和固定效应—在任何给定点处理随机效应结构或固定效果结构。

注2：不要将lmer模型与lm模型（或glmer与glm）进行比较。

## Entire model selection

关于选型过程的几点注意事项。这里有两种方法：（i）“自上而下”，从一个复杂的模型开始，逐渐减少它，以及（ii）“逐步”，从简单的模型开始并添加新的变量。不幸的是，使用这些策略可能会得到不同的最终模型，因此你需要小心。

Zuur等人（2009）推荐的模型选择过程是一种自上而下的策略，具体如下：

-   拟合一个完整的模型（他甚至建议“超越最优”，即比你预期或想要的更复杂）

-   整理随机效应结构（使用REML似然或REML AIC或BIC）

-   整理固定效应结构（要么使用REML的F统计量或t统计量，要么比较嵌套的ML模型—保持随机效应恒定）

-   一旦你到达最终模型，就使用REML估计来呈现它-

注意：冒着听起来像打破记录的风险：我认为最好根据生物学/生态学/数据结构等来决定你的模型是什么，而不是盲目地选择模型。此外，仅仅因为某事不重要并不一定意味着你应该总是摆脱它。

# The end

干得好！你可能会发现，混合效应模型可能有点棘手，而且对于解决其中问题的最佳方法往往没有达成太多共识。编码位实际上是这里（相对）容易的部分。注意你在做什么，准备好数据，一切都会好起来的。
